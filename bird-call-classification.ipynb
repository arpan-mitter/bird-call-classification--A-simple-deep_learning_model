{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87e560fc-8766-4ff6-ad6c-3a5fad835039",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Importing libraries and dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6339f51-0819-4085-a108-fb90bf909edd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from matplotlib import pyplot as plt\n",
    "import tensorflow as tf \n",
    "import tensorflow_io as tfio\n",
    "import csv\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, Dense, Flatten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1718e4a-e3f0-49b0-9049-7757c22ef314",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Building dataloading function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a35cde8-06d1-4955-bc78-bf1d3d4da060",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_wav_16k_mono(filename):\n",
    "    # Load encoded wav file\n",
    "    file_contents = tf.io.read_file(filename)\n",
    "    # Decode wav (tensors by channels) \n",
    "    wav, sample_rate = tf.audio.decode_wav(file_contents, desired_channels=1)\n",
    "    # Removes trailing axis\n",
    "    wav = tf.squeeze(wav, axis=-1)\n",
    "    sample_rate = tf.cast(sample_rate, dtype=tf.int64)\n",
    "    # Goes from 44100Hz to 16000hz - amplitude of the audio signal\n",
    "    wav = tfio.audio.resample(wav, rate_in=sample_rate, rate_out=16000)\n",
    "    return wav"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f6377ff-923a-4e04-9970-4ff0172b7886",
   "metadata": {},
   "outputs": [],
   "source": [
    "## creating dataflow in tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fa46b5c-154b-4725-b0e8-b6a636b943ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Define Paths to Positive and Negative Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "891aa8a1-2dd0-4fde-b268-f7898cc23a40",
   "metadata": {},
   "outputs": [],
   "source": [
    "POS = os.path.join('data', 'Parsed_Capuchinbird_Clips')\n",
    "NEG = os.path.join('data', 'Parsed_Not_Capuchinbird_Clips')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ade1125-6842-4c71-822b-14485290b929",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Create Tensorflow Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9459b82b-5bc6-4c9b-8cca-287f4dac246a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pos = tf.data.Dataset.list_files(POS+'\\*.wav')\n",
    "neg = tf.data.Dataset.list_files(NEG+'\\*.wav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42b63fe2-9333-4084-bef4-30fc10c76411",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Add labels and Combine Positive and Negative Samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a081d7f-a655-448f-b1c8-cb799db1f8b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "positives = tf.data.Dataset.zip((pos, tf.data.Dataset.from_tensor_slices(tf.ones(len(pos)))))\n",
    "negatives = tf.data.Dataset.zip((neg, tf.data.Dataset.from_tensor_slices(tf.zeros(len(neg)))))\n",
    "data = positives.concatenate(negatives)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59208e74-4ac8-4b8f-9cb8-977f24a19681",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Determine Average Length of a Capuchin Call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "785192f9-e4ef-4195-b7bf-39fd3a9920ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Calculate Wave Cycle Length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cabb00c-572e-460e-be07-9f1c361a3cda",
   "metadata": {},
   "outputs": [],
   "source": [
    "lengths = []\n",
    "for file in os.listdir(os.path.join('data', 'Parsed_Capuchinbird_Clips')):\n",
    "    tensor_wave = load_wav_16k_mono(os.path.join('data', 'Parsed_Capuchinbird_Clips', file))\n",
    "    lengths.append(len(tensor_wave))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5905de43-d00c-4a31-b3b6-c936e4fb36d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.math.reduce_mean(lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c58fa36-a5ff-4ab8-8365-160a2bb923e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.math.reduce_min(lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06bf6e24-fb4e-406a-90c0-90303566b6c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.math.reduce_max(lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3a3c044-3ad4-4aa0-9329-ad4c8763165f",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Build Preprocessing Function to Convert to Spectrogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a538cf74-5808-4e2d-acbe-981f762d1de0",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Build Preprocessing Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65aedd36-10db-4b44-89d6-8882bd2b2c67",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(file_path, label): \n",
    "    wav = load_wav_16k_mono(file_path)\n",
    "    wav = wav[:48000]\n",
    "    zero_padding = tf.zeros([48000] - tf.shape(wav), dtype=tf.float32)\n",
    "    wav = tf.concat([zero_padding, wav],0)\n",
    "    spectrogram = tf.signal.stft(wav, frame_length=320, frame_step=32)\n",
    "    spectrogram = tf.abs(spectrogram)\n",
    "    spectrogram = tf.expand_dims(spectrogram, axis=2)\n",
    "    return spectrogram, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3bec31a-8b48-44d9-91c6-74522e26031c",
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath, label = positives.shuffle(buffer_size=10000).as_numpy_iterator().next()\n",
    "\n",
    "spectrogram, label = preprocess(filepath, label)\n",
    "\n",
    "plt.figure(figsize=(30,20))\n",
    "plt.imshow(tf.transpose(spectrogram)[0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43ec295d-871c-47d1-b284-ab6380d3c56c",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Create Training and Testing Partitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26af6680-c772-4f3b-bab6-ddff622f9d38",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Create a Tensorflow Data Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f7968cd-6404-4f96-b98e-e2fe3bb74ab1",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.map(preprocess)\n",
    "data = data.cache()\n",
    "data = data.shuffle(buffer_size=1000)\n",
    "data = data.batch(16)\n",
    "data = data.prefetch(8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43ff2ec6-4d3e-44aa-a69a-467b5d04e638",
   "metadata": {},
   "outputs": [],
   "source": [
    "##splitting train and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61f68138-6c29-4822-a113-9b92d24d0358",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = data.take(36)\n",
    "test = data.skip(36).take(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d70e8688-1c83-4b68-89e7-6f9ccc04aa2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "##building deep learning model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe34d3f4-8f3b-40af-aa48-d0030fba848c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile('Adam', loss='BinaryCrossentropy', metrics=[tf.keras.metrics.Recall(),tf.keras.metrics.Precision()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77c27e33-72f6-4b70-9f08-f9e290f0580d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(16, (3,3), activation='relu', input_shape=(1491, 257,1)))\n",
    "model.add(Conv2D(16, (3,3), activation='relu'))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "549cb99e-b98d-4a50-833f-409d8129bbdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b630748a-7c7c-4da1-9ea1-07527c0ffbef",
   "metadata": {},
   "outputs": [],
   "source": [
    "##fiting model, calculating and plotting loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9a86cc3-d1d8-42ff-acaf-9c3775b227cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "hist = model.fit(train, epochs=4, validation_data=test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ef6295c-fe77-45bd-8ddf-82ba1b4eb4d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.title('Loss')\n",
    "plt.plot(hist.history['loss'], 'r')\n",
    "plt.plot(hist.history['val_loss'], 'b')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c35d2e1-46a9-4a98-b2fe-bf88a82495fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.title('Precision')\n",
    "plt.plot(hist.history['precision'], 'r')\n",
    "plt.plot(hist.history['val_precision'], 'b')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41b13817-9f7b-4163-a794-15f8a3eba86f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.title('Recall')\n",
    "plt.plot(hist.history['recall'], 'r')\n",
    "plt.plot(hist.history['val_recall'], 'b')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "223bdaa9-6c8c-417d-91cf-4b9540b1d97b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## making prediction on a single batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21963c23-7845-4b62-ac78-a84f2cfb4475",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test, y_test = test.as_numpy_iterator().next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3902c7a2-0ff0-4337-8fda-3411ad80e6fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fbb09a1-6c08-45f1-a4ed-cf25c43349d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "##coverting logits to classifier classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c98a9647-b85d-4fd6-860b-d584893ccfb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat = [1 if prediction > 0.5 else 0 for prediction in yhat]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3f2d202-7a25-4f8a-b826-8ea314015575",
   "metadata": {},
   "outputs": [],
   "source": [
    "## building parsing function for forest dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66480f39-6e4a-42e9-96da-63a75835415d",
   "metadata": {},
   "outputs": [],
   "source": [
    "##loading up mp3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "838eb889-5158-471a-9500-f36db3cd0645",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_mp3_16k_mono(filename):\n",
    "    \"\"\" Load a WAV file, convert it to a float tensor, resample to 16 kHz single-channel audio. \"\"\"\n",
    "    res = tfio.audio.AudioIOTensor(filename)\n",
    "    # Convert to tensor and combine channels \n",
    "    tensor = res.to_tensor()\n",
    "    tensor = tf.math.reduce_sum(tensor, axis=1) / 2 \n",
    "    # Extract sample rate and cast\n",
    "    sample_rate = res.rate\n",
    "    sample_rate = tf.cast(sample_rate, dtype=tf.int64)\n",
    "    # Resample to 16 kHz\n",
    "    wav = tfio.audio.resample(tensor, rate_in=sample_rate, rate_out=16000)\n",
    "    return wav"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "626c5fb2-5c6e-4acb-95de-1f693cec75d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "wav = load_mp3_16k_mono(mp3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cafa2261-9f36-4beb-810a-beeed0363c7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_slices = tf.keras.utils.timeseries_dataset_from_array(wav, wav, sequence_length=48000, sequence_stride=48000, batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f473fc63-f65d-470d-861e-2bbd7766435b",
   "metadata": {},
   "outputs": [],
   "source": [
    "samples, index = audio_slices.as_numpy_iterator().next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "678047ed-81fb-4ade-940e-1a9778f33706",
   "metadata": {},
   "outputs": [],
   "source": [
    "mp3 = os.path.join('data', 'Forest Recordings', 'recording_00.mp3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f5294e8-2f5a-430e-a626-74aa2be46a63",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Build Function to Convert Clips into Windowed Spectrograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "887a36a7-a318-498d-ac00-e487e98990e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_mp3(sample, index):\n",
    "    sample = sample[0]\n",
    "    zero_padding = tf.zeros([48000] - tf.shape(sample), dtype=tf.float32)\n",
    "    wav = tf.concat([zero_padding, sample],0)\n",
    "    spectrogram = tf.signal.stft(wav, frame_length=320, frame_step=32)\n",
    "    spectrogram = tf.abs(spectrogram)\n",
    "    spectrogram = tf.expand_dims(spectrogram, axis=2)\n",
    "    return spectrogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "470d9525-5fb0-4c0a-8e37-c5de1ba52d38",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Convert Longer Clips into Windows and Make Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ac07b87-2bd0-408f-b8e2-8a5eb0ddee11",
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_slices = tf.keras.utils.timeseries_dataset_from_array(wav, wav, sequence_length=16000, sequence_stride=16000, batch_size=1)\n",
    "audio_slices = audio_slices.map(preprocess_mp3)\n",
    "audio_slices = audio_slices.batch(64)\n",
    "yhat = model.predict(audio_slices)\n",
    "yhat = [1 if prediction > 0.5 else 0 for prediction in yhat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c2aa6fc-1d36-4db6-9344-936bd74fdf4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Group Consecutive Detections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "248a3b63-5886-415c-b67c-6dbf56ca4665",
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import groupby"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84b741d7-fe0d-49b5-a64b-6119165ee4e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat = [key for key, group in groupby(yhat)]\n",
    "calls = tf.math.reduce_sum(yhat).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a45562c-cf1d-4a05-908f-791d13663977",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Make Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56ed772d-6311-4389-b7d0-755cee09b8b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Loop over all recordings and make predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eeadb1a-93ff-4009-a88a-6cc0ab34f8e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {}\n",
    "for file in os.listdir(os.path.join('data', 'Forest Recordings')):\n",
    "    FILEPATH = os.path.join('data','Forest Recordings', file)\n",
    "    \n",
    "    wav = load_mp3_16k_mono(FILEPATH)\n",
    "    audio_slices = tf.keras.utils.timeseries_dataset_from_array(wav, wav, sequence_length=48000, sequence_stride=48000, batch_size=1)\n",
    "    audio_slices = audio_slices.map(preprocess_mp3)\n",
    "    audio_slices = audio_slices.batch(64)\n",
    "    \n",
    "    yhat = model.predict(audio_slices)\n",
    "    \n",
    "    results[file] = yhat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8024885-ccd0-4532-bcfc-d810450eb2f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Convert Predictions into Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ff12e11-11cf-493a-b801-e3572951f05f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_preds = {}\n",
    "for file, logits in results.items():\n",
    "    class_preds[file] = [1 if prediction > 0.99 else 0 for prediction in logits]\n",
    "class_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7728b660-334c-4124-b277-8dee18d83e3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Group Consecutive Detections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5331de0e-3b8a-4610-8b2f-3f8a85a5d548",
   "metadata": {},
   "outputs": [],
   "source": [
    "postprocessed = {}\n",
    "for file, scores in class_preds.items():\n",
    "    postprocessed[file] = tf.math.reduce_sum([key for key, group in groupby(scores)]).numpy()\n",
    "postprocessed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca0575ff-6df2-4646-957f-9bab3e345870",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Export Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "712739f1-22d8-48d7-85ed-43a2c964427f",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('results.csv', 'w', newline='') as f:\n",
    "    writer = csv.writer(f, delimiter=',')\n",
    "    writer.writerow(['recording', 'capuchin_calls'])\n",
    "    for key, value in postprocessed.items():\n",
    "        writer.writerow([key, value])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1efb3b48-f57d-40e6-a4b7-02b491b89bc5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
